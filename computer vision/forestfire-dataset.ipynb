{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4932759,"sourceType":"datasetVersion","datasetId":2860500}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #for data augumentation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport tkinter as tk\nfrom tkinter import filedialog #provides a dialog box to select files.\nfrom PIL import Image, ImageTk #ImageTk - Converts images for display in Tkinter GUIs\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T07:48:39.182826Z","iopub.execute_input":"2025-01-17T07:48:39.183231Z","iopub.status.idle":"2025-01-17T07:48:54.603367Z","shell.execute_reply.started":"2025-01-17T07:48:39.183202Z","shell.execute_reply":"2025-01-17T07:48:54.602229Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set up directories\ntrain_dir = r\"/kaggle/input/wildfire-prediction-dataset/train\"\nvalid_dir = r\"/kaggle/input/wildfire-prediction-dataset/valid\"\ntest_dir = r\"/kaggle/input/wildfire-prediction-dataset/test\"\n\n# Set up ImageDataGenerators for loading images\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load images from directories\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\nvalid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\ntest_generator = test_datagen.flow_from_directory(test_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T07:48:54.604643Z","iopub.execute_input":"2025-01-17T07:48:54.605311Z","iopub.status.idle":"2025-01-17T07:49:14.410567Z","shell.execute_reply.started":"2025-01-17T07:48:54.605273Z","shell.execute_reply":"2025-01-17T07:49:14.409547Z"}},"outputs":[{"name":"stdout","text":"Found 30250 images belonging to 2 classes.\nFound 6300 images belonging to 2 classes.\nFound 6300 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Building a simple CNN model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # Binary classification: wildfire or no wildfire\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T07:49:14.412135Z","iopub.execute_input":"2025-01-17T07:49:14.412420Z","iopub.status.idle":"2025-01-17T07:49:14.551243Z","shell.execute_reply.started":"2025-01-17T07:49:14.412396Z","shell.execute_reply":"2025-01-17T07:49:14.550142Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T07:49:14.552236Z","iopub.execute_input":"2025-01-17T07:49:14.552539Z","iopub.status.idle":"2025-01-17T07:49:14.556511Z","shell.execute_reply.started":"2025-01-17T07:49:14.552513Z","shell.execute_reply":"2025-01-17T07:49:14.555435Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_generator, validation_data=valid_generator, epochs=2, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T07:49:14.557695Z","iopub.execute_input":"2025-01-17T07:49:14.558080Z","iopub.status.idle":"2025-01-17T07:55:09.513338Z","shell.execute_reply.started":"2025-01-17T07:49:14.558044Z","shell.execute_reply":"2025-01-17T07:55:09.512455Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 236ms/step - accuracy: 0.8820 - loss: 0.2759 - val_accuracy: 0.9368 - val_loss: 0.1698\nEpoch 2/2\n\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 135ms/step - accuracy: 0.9324 - loss: 0.1828 - val_accuracy: 0.9440 - val_loss: 0.1519\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#save the model\nmodel.save(\"ffd_model.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T08:12:48.373370Z","iopub.execute_input":"2025-01-17T08:12:48.373711Z","iopub.status.idle":"2025-01-17T08:12:48.408272Z","shell.execute_reply.started":"2025-01-17T08:12:48.373683Z","shell.execute_reply":"2025-01-17T08:12:48.407209Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import tkinter as tk\nfrom tkinter import filedialog  \n\nfrom PIL import Image, ImageTk  \nimport numpy as np  \nimport tensorflow as tf  \n\nfrom tensorflow.keras.models import load_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T08:12:53.206001Z","iopub.execute_input":"2025-01-17T08:12:53.206322Z","iopub.status.idle":"2025-01-17T08:12:53.210933Z","shell.execute_reply.started":"2025-01-17T08:12:53.206299Z","shell.execute_reply":"2025-01-17T08:12:53.209819Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Load the model\nmodel = load_model(\"ffd_model.h5\")\nprint(\"Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T08:12:59.948459Z","iopub.execute_input":"2025-01-17T08:12:59.948783Z","iopub.status.idle":"2025-01-17T08:13:00.042887Z","shell.execute_reply.started":"2025-01-17T08:12:59.948754Z","shell.execute_reply":"2025-01-17T08:13:00.041971Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Function to load and predict an image\ndef predict_image():\n    # Open file dialog to select an image\n    file_path = filedialog.askopenfilename()\n    if file_path:\n        # Display the image in the GUI\n        img = Image.open(file_path)\n        img = img.resize((200, 200))\n        img = ImageTk.PhotoImage(img)    #convert image for tk\n        image_label.configure(image=img) #update the image in GUI\n        image_label.image = img\n\n        # Preprocess the image for the model\n        img_for_model = Image.open(file_path).resize((64, 64))\n        img_array = np.array(img_for_model) / 255.0  # Rescale like during training\n        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n\n        # Make a prediction\n        prediction = model.predict(img_array)[0][0] #extracts the scalar prediction value\n        result = \"Wildfire\" if prediction > 0.5 else \"No Wildfire\"\n        result_label.config(text=\"Prediction: \" + result)\n\n# Setting up the GUI window\nroot = tk.Tk()\nroot.title(\"Forest Fire Detection\")\nroot.geometry(\"400x400\")\n\n# Add widgets\nbtn = tk.Button(root, text=\"Upload Image\", command=predict_image) #button triggers the predict_image() function when clicked\nbtn.pack(pady=20)\n\n#Placeholder for displaying the selected image\nimage_label = tk.Label(root)\nimage_label.pack()\n\n#Label to display the prediction result\nresult_label = tk.Label(root, text=\"Prediction: \", font=(\"Helvetica\", 16))\nresult_label.pack(pady=20)\n\n#Starts the Tkinter event loop, keeping the GUI active until manually closed\nroot.mainloop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T08:13:03.895699Z","iopub.execute_input":"2025-01-17T08:13:03.896160Z","iopub.status.idle":"2025-01-17T08:13:03.922061Z","shell.execute_reply.started":"2025-01-17T08:13:03.896129Z","shell.execute_reply":"2025-01-17T08:13:03.920342Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-5645b28c7fd9>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Setting up the GUI window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Forest Fire Detection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"400x400\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"],"ename":"TclError","evalue":"no display name and no $DISPLAY environment variable","output_type":"error"}],"execution_count":23}]}